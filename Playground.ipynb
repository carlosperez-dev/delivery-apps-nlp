{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053e6b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#from transformers import pipeline\n",
    "#!pip install emoji\n",
    "import emoji\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf127b7",
   "metadata": {},
   "source": [
    "From the google play store we have scraped reviews for grocery store apps delivery apps: Tesco, Morrisons, M&S, ASDA, Aldi, Sainbury's and Waitrose. Parameters for scraping were set to 300 for reviews with 1 and 2 stars and 250 for 4, and 5 stars and only 150 with 3 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df = pd.read_csv(\"src/reviews.csv\")\n",
    "app_infos_df = pd.read_csv(\"src/apps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07880fde",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e159b",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Check the number of reviews scraped for each company</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = app_reviews_df['appId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reviews_per_star(df):\n",
    "    apps = df['appId'].unique()\n",
    "    for app in apps:\n",
    "        name = app.split('.')[1].title() if app != 'de.apptiv.business.android.aldi_uk' else app.split('.')[-1].split('_')[0].title()\n",
    "        print(name, \"reviews per star:\")\n",
    "        stars = df['score'].loc[df['appId'] == app].value_counts()\n",
    "        total = sum(stars)\n",
    "        print(stars)\n",
    "        print('Total # of reviews:',total)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d73518",
   "metadata": {},
   "source": [
    "### Table 1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24726b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_reviews_per_star(app_reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76db3a2",
   "metadata": {},
   "source": [
    "From the reviews, Morrisons and Waitrose scraped less reviess with 3,2, and 4 stars due to availability however at the extremes (1 and 5 stars) it's the same as others - as expected. As we aim to extract recommendations, the 1 star reviews will have vital importance however we proceed with cautions given the lower sample size relative to other apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c2149d",
   "metadata": {},
   "source": [
    "<ol start='2'>\n",
    "    <li>Check for missing values</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cc4f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in app_reviews_df.columns:\n",
    "    print(\"Missing values in\", column, \": {}\".format(app_reviews_df[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba15e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['reviewCreatedVersion'] == '19.29.0'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55295552",
   "metadata": {},
   "source": [
    "Further inspection shows that 'reviewCreatedVersion' is the version of the app the user reviewed. Therefore, we can potentially narrow down the comments by the version of the app rather than dates. Alternatively, I can use the date as a proxy for the created version so will keep those. Regarding the replyContent and repliedAt, doesn't really matter as these just represent whether the company replied or not but worth visualising just in case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f6427",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['replyContent'].notnull()]['appId'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913573b",
   "metadata": {},
   "source": [
    "We can see that waitrose is significantly better at replying to comment, with the next company being aldi (a budget supermaket) surprisingly. Aldi, on the other hand, has not replied to anyone. Next questions is, are they replying to good reviews or bad reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded508e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for app in apps:\n",
    "    print(app)\n",
    "    print(app_reviews_df.loc[(app_reviews_df['appId'] == app) & (app_reviews_df['replyContent'].notnull() == True)]['score'].value_counts())\n",
    "    print('\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1adbc5",
   "metadata": {},
   "source": [
    "Waitrose mainly responds to low reviews <= 3 stars with most of the responses going to 1 star, M&S responds mainly to 2 and 1 stars, morrisons loves the praise only 4&5 stars. Aldi no reply to 1 stars but only to 2 and 3 stars. Tesco likes praise but has responded to a (1) 2 star and (1) 3 star review. Sainsburys also likes praise with 2 out of 3 responses going to 4 and 5 stars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dfe9f1",
   "metadata": {},
   "source": [
    "### Table 2a - code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631e58d",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Number of words per comment on avg.</li>\n",
    "    <li>Number of sentences per comment on avg.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_segmentation(df):\n",
    "    reviews_in_sents = []\n",
    "    number_of_sents = 0\n",
    "    for review in df['content']:\n",
    "        sentences = nltk.sent_tokenize(review)\n",
    "        number_of_sents += len(sentences)\n",
    "        reviews_in_sents.append(sentences)\n",
    "    return reviews_in_sents, number_of_sents\n",
    "\n",
    "reviews_in_sents, number_of_sents = sentence_segmentation(app_reviews_df)\n",
    "print(f'There is approx. {round(number_of_sents/len(reviews_in_sents),2)} sentences per review.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df['reviews_in_sents'] = reviews_in_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e109ac",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "    <li>Check the date for the latest updated of the app and the number of reviews after the date.</li>\n",
    "    <ul>\n",
    "        <li>Tesco: <b>30 March 2022</b></li>\n",
    "        <li>Morrison: <b>9 March 2022</b></li>\n",
    "        <li>Marks and Spencers: <b>24 March 2022</b></li>    \n",
    "        <li>ASDA: <b>29 March 2022</b></li>    \n",
    "        <li>ALDI: <b>28 February 2022</b></li>    \n",
    "        <li>Sainsbury's: <b>25 March 2022</b></li>    \n",
    "        <li>Waitrose: <b>25 March 2022</b></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "   <li>Check what the recent changes made are.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308ae48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for changes in app_infos_df.iloc[:, 44]:\n",
    "    name = app_infos_df['title'][i]\n",
    "    print(name,'changes :', changes)\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2865f",
   "metadata": {},
   "source": [
    "From the notes pertaining to the recent changes implemented to the apps, it's unclear if the existing reviews have been analysed as part of the process to create/improve features hence it will be difficult to know when an issue has been addressed by a new version of the app. In addittion, following the dates in which the apps were last updated we can't single out issue which are still present in the current version due to the lack of reviews from the date of update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc7da8",
   "metadata": {},
   "source": [
    "<ol start=\"5\">\n",
    "    <li>Check the date of the earliest review for each company.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d471927",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app_reviews_df['appId'].unique()\n",
    "for app in app_reviews_df['appId'].unique():\n",
    "    name = app.split('.')[1].title() if app != 'de.apptiv.business.android.aldi_uk' else app.split('.')[-1].split('_')[0].title()\n",
    "    date = app_reviews_df.loc[app_reviews_df['appId'] == app]['at'].min()  \n",
    "    #print(type(date))\n",
    "    print(name,':',date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537c0c1",
   "metadata": {},
   "source": [
    "Given that some apps have reviews as early as 2011, and given the lack of infomration related to information on changes made per version <b>I will narrow down the comments per company to include a maximum of the last 12 months.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6453dce6",
   "metadata": {},
   "source": [
    "<ol start=\"6\">\n",
    "    <li>Check the comment with the most upvotes.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088437f",
   "metadata": {},
   "source": [
    "### Table 2b code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853f546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for app in apps:\n",
    "    name = app.split('.')[1].title() if app != 'de.apptiv.business.android.aldi_uk' else app.split('.')[-1].split('_')[0].title()\n",
    "    votes = app_reviews_df.loc[app_reviews_df['appId'] == app]['thumbsUpCount'].max()  \n",
    "    review = app_reviews_df.loc[(app_reviews_df[\"appId\"] == app) & (app_reviews_df[\"thumbsUpCount\"] == votes), 'content'].value_counts()\n",
    "    idx = app_reviews_df.loc[(app_reviews_df[\"appId\"] == app) & (app_reviews_df[\"thumbsUpCount\"] == votes), 'content'].index[0]\n",
    "    date = app_reviews_df['at'][idx].split(' ')[0]\n",
    "    print(name)\n",
    "    print('Date published:', date, '    ', votes, 'likes' )\n",
    "    print(review)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c47656",
   "metadata": {},
   "source": [
    "In the case of Tesco (January), Marks and Spencers (March), Asda (March), and Waitrose (March) the most liked comments are all as of 2022 i.e. recent issues. On the other hand, Sainsbury's (October), Aldi (November), and Morrisons (April) are all from 2021. <br><b>Further investigation required, perhaps look at the most liked comment in the last 3 or 6 months only</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7888f61",
   "metadata": {},
   "source": [
    "<ol start=\"7\">\n",
    "    <li>Extend the dataframe to include: word count and sentence count.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_comments(df):\n",
    "    tokenised_comms = []\n",
    "    for i in df['content']:\n",
    "        tknzr = TweetTokenizer()\n",
    "        s_tweettok = tknzr.tokenize(i)\n",
    "        tokenised_comms.append(s_tweettok)\n",
    "    return tokenised_comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(toks_words):\n",
    "    remove_these = set(list(string.punctuation) + list(string.digits))\n",
    "    removed_punct = []\n",
    "    for review in toks_words:\n",
    "        review_words = []\n",
    "        for word in review:\n",
    "            if not word in remove_these:\n",
    "                review_words.append(word)\n",
    "        removed_punct.append(review_words)\n",
    "    return removed_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df['sentence_count'] = [len(review) for review in app_reviews_df['reviews_in_sents']]\n",
    "app_reviews_df['reviews_in_words'] = tokenise_comments(app_reviews_df)\n",
    "app_reviews_df['word_count'] = [len(review) for review in remove_punctuations(app_reviews_df['reviews_in_words'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463000a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1852e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,3,figsize=(12,4), sharey=False)\n",
    "sns.distplot(app_reviews_df.thumbsUpCount, ax=ax[0])\n",
    "ax[0].set_title(\"Thumb Up Count Distribution\")\n",
    "ax[0].set_xlabel(\"Number of Thumbs up\")\n",
    "sns.distplot(app_reviews_df.sentence_count, ax=ax[1])\n",
    "ax[1].set_title(\"Sentence Count Distribution\")\n",
    "ax[1].set_xlabel(\"Number of Sentences\")\n",
    "sns.distplot(app_reviews_df.word_count, ax=ax[2])\n",
    "ax[2].set_title(\"Word Count Distribution\")\n",
    "ax[2].set_xlabel(\"Number of Words\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a76b8b",
   "metadata": {},
   "source": [
    "Only abnormality was the comement with 0 words and 1 sentence, turns out is just a period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99fbec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['word_count'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11902c7",
   "metadata": {},
   "source": [
    "<ol start=\"8\">\n",
    "    <li>Count of review per app version.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df['ymd'] = [date.split(' ')[0] for date in app_reviews_df['at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df['time'] =[date.split(' ')[1] for date in app_reviews_df['at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58312b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['time'] >'00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86623f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['ymd'] >'2022-03-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67aa80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for app in apps:\n",
    "    print(app,':', len(app_reviews_df.loc[app_reviews_df['appId'] == app]['reviewCreatedVersion'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd631972",
   "metadata": {},
   "source": [
    "The apps seem to be updated very frequently with over 429 versions. Tesco has had 16 versions, morrisons 89, M&S 62, Aldi 73, Sainsburys 74, Waitrose 72."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f08e2",
   "metadata": {},
   "source": [
    "### Make Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fbd601",
   "metadata": {},
   "source": [
    "Make label of pos, neg, neutral based on score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae43848",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for score in app_reviews_df['score']:\n",
    "    if score < 3:\n",
    "        scores.append('neg')\n",
    "    elif score > 3:\n",
    "        scores.append('pos')\n",
    "    else:\n",
    "        scores.append('neu')\n",
    "        \n",
    "app_reviews_df['label'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a07a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app_reviews_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_speech(comments, pos): \n",
    "    all_words = []\n",
    "    i = 0\n",
    "    for review in comments:\n",
    "        all_words.append(remove_stopwords(review))\n",
    "        i += 1    \n",
    "    words = []\n",
    "    for review in all_words:\n",
    "        for word, pos_code in nltk.pos_tag(review):\n",
    "            pos_to_add = []\n",
    "            if pos_code in pos:\n",
    "                pos_to_add.append(word)\n",
    "        words.append(pos_to_add)\n",
    "        \n",
    "    return words \n",
    "\n",
    "def remove_stopwords(toks_words, type_of_gram = 'none'):\n",
    "    if type_of_gram =='bi':\n",
    "        stopwords = ['to', 'the', 'have', 'on', 'in', 'is', 'this', 'and', 'i',\n",
    "                 'you', 'of', 'be', 'for', 'my', 'that', 'a', 'very', 'there']\n",
    "    elif type_of_gram == 'tri':\n",
    "        stopwords = ['and', 'to', 'the']\n",
    "    else:\n",
    "        stopwords = ['..', ',']\n",
    "    remove_these = set(stopwords + list(string.punctuation) + list(string.digits))\n",
    "    filtered_text = [word for word in toks_words if not word in remove_these]\n",
    "    return filtered_text\n",
    "\n",
    "def make_dist_plot(column, number_of_words):\n",
    "    flat_list = [item for sublist in column for item in sublist]\n",
    "    fdist = FreqDist(flat_list)\n",
    "    return fdist.plot(number_of_words,title=f'Frequency distribution for {number_of_words} most common tokens in our collection.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b3fe3",
   "metadata": {},
   "source": [
    "Make review_in_words lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd4229",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_dist_plot(app_reviews_df['reviews_in_words'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c52534",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for review in app_reviews_df['reviews_in_words']:\n",
    "    review_lower = []\n",
    "    for word in review:\n",
    "        review_lower.append(word.lower())\n",
    "    all_words.append(review_lower)\n",
    "    \n",
    "app_reviews_df['reviews_in_words'] = all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf4a1f",
   "metadata": {},
   "source": [
    "Make label using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f79a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySentenceVADER(reviews_in_sens):\n",
    "    sid = SIA()\n",
    "    labels = []\n",
    "    for review in reviews_in_sens:\n",
    "        overall_score = 0\n",
    "        for sentence in review:\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            overall_score += ss['compound'] \n",
    "        if overall_score == 0.0:\n",
    "            labels.append('neu')\n",
    "        elif overall_score > 0:\n",
    "            labels.append('pos')\n",
    "        elif overall_score < 0 :\n",
    "            labels.append('neg')\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278df239",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app_reviews_df['vader_label'] = classifySentenceVADER(app_reviews_df['reviews_in_sents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b42d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['label'] != app_reviews_df['vader_label']]['vader_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b707b",
   "metadata": {},
   "source": [
    "We can see that the VADER classifier is not the best, whilst it does classify properly large number of reviews. It has clear discrepancies with those set with the heurisitc of >3 positive <3 negative and 3 stars neutral. With there being 1243 reviews it classifies as neutral which are not neutral in terms of stars, a closer look sees that the classifier in multiple case is unable to determine the sentiment so gives it a score of 0.0 i.e. neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87862e7",
   "metadata": {},
   "source": [
    "Using TextBlob to check performance and compare VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555286b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "app_reviews_df['textblob_label'] = app_reviews_df['content'].apply(pol)\n",
    "app_reviews_df['textblob_label'] = ['pos' if label > 0 else 'neg' if label < 0 else 'neu' for label in app_reviews_df['textblob_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1883df5",
   "metadata": {},
   "source": [
    "Using HuggingFace BERT Base model to check performance and compare VADER and TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb2324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specific_model = pipeline(model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_score = []\n",
    "for review in app_reviews_df['content']:\n",
    "    star = specific_model(review)[0]['label'].split(' ')[0]\n",
    "    bert_score.append(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df['bert_score'] = bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd408c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for score in app_reviews_df['bert_score']:\n",
    "    if int(score) < 3:\n",
    "        scores.append('neg')\n",
    "    elif int(score) > 3:\n",
    "        scores.append('pos')\n",
    "    else:\n",
    "        scores.append('neu')\n",
    "        \n",
    "app_reviews_df['bert_label'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403d33e",
   "metadata": {},
   "source": [
    "Significant improvement in using BERT to classify the reviews, nearly cuts the mislabeling between pos/neg/neutral by half. Served as a training for use of future unsupervised problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945990f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app_reviews_df.loc[app_reviews_df['replyContent'].notna()]['replyContent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df279b",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df.to_csv('src/reviews_1.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bab01",
   "metadata": {},
   "source": [
    "Explore extracting topics from the reviews by selecting nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc5320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_specific_speech(app_reviews_df['reviews_in_words'], ['NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aadf816",
   "metadata": {},
   "source": [
    "Not enough nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acd2ef",
   "metadata": {},
   "source": [
    "Normalise words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in app_reviews_df['reviews_in_words']:\n",
    "    for index, word in enumerate(review):\n",
    "        if (index+1 < len(review) and index - 1 >= 0):\n",
    "            prev_el = str(review[index-1])\n",
    "            curr_el = str(word)\n",
    "            next_el = str(review[index+1])\n",
    "            #print(prev_el, curr_el, next_el)\n",
    "            if (prev_el == 'check' and curr_el == 'out') or (prev_el == 'club' and curr_el == 'card') or (prev_el == 'log' and curr_el == 'out') or (prev_el == 'log' and curr_el == 'in') or (prev_el == 'spark' and curr_el == 'card') or (prev_el == 'out' and curr_el == 'stock'):\n",
    "                review[index-1:index] = [''.join(review[index-1:index])]\n",
    "            elif (curr_el == 'check' and next_el == 'out') or (curr_el == 'club' and next_el == 'card') or (curr_el == 'log' and next_el == 'out') or (curr_el == 'log' and next_el == 'in') or (curr_el == 'spark' and next_el == 'card') or (curr_el == 'out' and next_el == 'stock'):\n",
    "                review[index:index+2] = [''.join(review[index:index+2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2284e3af",
   "metadata": {},
   "source": [
    "Lemmaatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "POS_LIST = [NOUN, VERB, ADJ, ADV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddacce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def nltk_pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    print(nltk_tagged)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_pos_tagger(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    \n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "print(lemmatize_sentence(\"I am voting for that politician in this NLTK Lemmatization example sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ea850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmatized_sentence = []\n",
    "for review in app_reviews_df['reviews_in_words']:\n",
    "    nltk_tagged = nltk.pos_tag(review)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_pos_tagger(x[1])), nltk_tagged)\n",
    "    review_lem = []\n",
    "    #print(wordnet_tagged)\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            review_lem.append(word)\n",
    "        else:        \n",
    "            review_lem.append(lemmatizer.lemmatize(word, tag))\n",
    "    lemmatized_sentence.append(review_lem)\n",
    "    \n",
    "app_reviews_df['reviews_lemmatized'] = lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc6013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3ce1b",
   "metadata": {},
   "source": [
    "Words that are nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbec1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_specific_speech(app_reviews_df['reviews_lemmatized'], ['NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd339e",
   "metadata": {},
   "source": [
    "### Split df by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574f108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_df(df, column, value):\n",
    "    new_df = df[df[column] == value]\n",
    "    return new_df\n",
    "\n",
    "def split_per_app(df, column_with_names):\n",
    "    all_dfs = [] \n",
    "    apps = df[column_with_names].unique()\n",
    "    for app in apps:\n",
    "        name = split_df(df, column_with_names, app)\n",
    "        all_dfs.append(name)  \n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_reviews = split_per_app(app_reviews_df, 'appId')\n",
    "\n",
    "tesco_reviews = split_reviews[0]\n",
    "morrisons_reviews = split_reviews[1]\n",
    "marksandspencer_reviews = split_reviews[2]\n",
    "asda_reviews = split_reviews[3]\n",
    "aldi_reviews = split_reviews[4]\n",
    "sainsburys_reviews = split_reviews[5]\n",
    "waitrose_reviews = split_reviews[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "morrisons_reviews.reset_index(inplace = True, drop = True)\n",
    "marksandspencer_reviews.reset_index(inplace = True, drop = True)\n",
    "asda_reviews.reset_index(inplace = True, drop = True)\n",
    "aldi_reviews.reset_index(inplace = True, drop = True)\n",
    "sainsburys_reviews.reset_index(inplace = True, drop = True)\n",
    "waitrose_reviews.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e6455",
   "metadata": {},
   "source": [
    "Distribution of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c513e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_dist_plot(tesco_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41d2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_dist_plot(morrisons_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dist_plot(marksandspencer_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dist_plot(asda_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dist_plot(aldi_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dist_plot(sainsburys_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6ada9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_dist_plot(waitrose_reviews['reviews_lemmatized'], 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24eea9",
   "metadata": {},
   "source": [
    "Bigrams and trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64009127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "def get_ngram(lemma_column, number_of_words, n):\n",
    "    if type(lemma_column[0]) is not str:\n",
    "        flat_list = [item for sublist in lemma_column for item in sublist]\n",
    "    else:\n",
    "        flat_list = lemma_column\n",
    "    ngram = [b for b in ngrams(flat_list, n)]\n",
    "    freq_ngrams = nltk.FreqDist(ngram)\n",
    "    #print(freq_ngrams.most_common(number_of_words)) \n",
    "    #fdist = FreqDist(freq_ngrams)\n",
    "    #fdist.plot(number_of_words,title=f'Frequency distribution for {number_of_words} most common tokens in our collection.')\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb19dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_2(lemma_column, type_of_gram):\n",
    "    flat_list = [item for sublist in lemma_column for item in sublist]\n",
    "    if type_of_gram =='Bi':\n",
    "        new_stopwords = ['to', 'the', 'have', 'on', 'in', 'is', 'this', 'and', 'i',\n",
    "                 'you', 'of', 'be', 'for', 'my', 'that', 'a', 'very', 'there', '...', '..', ',', 'do', 'not',\n",
    "                        'it', \"doesn't\", 'let', 'me', 'every', 'longer', 'even', 'though', 'too', 'an', 'use',\n",
    "                        'rather', 'through', 'your', 'more', 'now', 'keep', 'but', 'at','all',\"can't\", 'with',\n",
    "                        \"won't\",'when', 'sort', 'please', 'need', 'app', 'easy', 'quick']\n",
    "    elif type_of_gram == 'Tri':\n",
    "        new_stopwords = ['and', 'to', 'the', 'i', 'you', 'this', 'a', 'me', 'be', 'very', 'it', '...', '..', ',',\n",
    "                        'for','of', 'easy', 'quick']\n",
    "    else:\n",
    "        new_stopwords = ['..', ',', '...']\n",
    "    remove_these = set(new_stopwords + list(string.punctuation) + list(string.digits))# + stopwords.words('english'))\n",
    "    filtered_text = [word for word in flat_list if not word in remove_these]\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_by_label(df, stopwords, number_of_grams, n_grams,  label, color):\n",
    "    pos_df = df.loc[df['label'] == label]\n",
    "    ngrams = get_ngram(remove_stopwords_2(pos_df['reviews_lemmatized'], stopwords), number_of_grams, n_grams)\n",
    "    ngrams_series = pd.Series(ngrams).value_counts()[0:number_of_grams]\n",
    "    plt.title(f'{number_of_grams} Most Frequently Occuring {stopwords}grams')\n",
    "    plt.ylabel(f'{stopwords}gram')\n",
    "    plt.xlabel('# of Occurances')\n",
    "    ngrams_series.sort_values().plot.barh(color=color, width=.9, figsize=(12, 8))\n",
    "    plt.savefig('graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0234739",
   "metadata": {},
   "source": [
    "### Figure 3 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f1c19",
   "metadata": {},
   "source": [
    "## Tesco's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee5c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(tesco_reviews, 'Bi', 10, 2, 'neg', 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523daa15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(tesco_reviews, 'Tri', 10, 3, 'neg', 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5754d",
   "metadata": {},
   "source": [
    "## Morrison's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb53cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ngram_by_label(morrisons_reviews, 'Bi', 10, 2, 'pos', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75613da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(morrisons_reviews, 'Tri', 10, 3, 'pos', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55224ba",
   "metadata": {},
   "source": [
    "## M&S's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5073d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(marksandspencer_reviews, 'Bi', 10, 2, 'pos', 'grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a306f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_by_label(marksandspencer_reviews, 'Tri', 10, 3, 'pos', 'grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875616d5",
   "metadata": {},
   "source": [
    "## Asda's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8551f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_by_label(asda_reviews, 'Bi', 10, 2, 'pos', 'lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501358d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ngram_by_label(asda_reviews, 'Tri', 10, 3, 'pos', 'lightgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352943d",
   "metadata": {},
   "source": [
    "## ALDI's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0eddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_by_label(aldi_reviews, 'Bi', 10, 2, 'pos', 'lightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615a838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(aldi_reviews, 'Tri', 10, 3, 'pos', 'lightblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99eb375",
   "metadata": {},
   "source": [
    "## Sainsbury's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140bf50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(sainsburys_reviews, 'Bi', 3, 2, 'neg', 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14bcbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(sainsburys_reviews, 'Tri', 4, 3, 'neg', 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c2f82",
   "metadata": {},
   "source": [
    "## Waitrose's bi/trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b44df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_by_label(waitrose_reviews, 'Bi', 10, 2, 'pos', 'lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06abaece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngram_by_label(waitrose_reviews, 'Tri', 10, 3, 'pos', 'lightgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4544a3",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesco_reviews.to_csv('src/tesco_reviews_2.csv', index=None, header=True)\n",
    "morrisons_reviews.to_csv('src/morrisons_reviews_2.csv', index=None, header=True)\n",
    "marksandspencer_reviews.to_csv('src/marksandspencer_reviews_2.csv', index=None, header=True)\n",
    "asda_reviews.to_csv('src/asda_reviews_2.csv', index=None, header=True)\n",
    "aldi_reviews.to_csv('src/aldi_reviews_2.csv', index=None, header=True)\n",
    "sainsburys_reviews.to_csv('src/sainsburys_reviews_2.csv', index=None, header=True)\n",
    "waitrose_reviews.to_csv('src/waitrose_reviews_2.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d132a5",
   "metadata": {},
   "source": [
    "### Figure 4 code - Get wordcloud of adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_for_wordcloud = get_specific_speech(sainsburys_reviews['reviews_lemmatized'], ['JJ', 'JJR', 'JJS'])\n",
    "filter_for_wordcloud = [word for review in filter_for_wordcloud for word in review ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde72963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdist_filtered = FreqDist(filter_for_wordcloud)\n",
    "print(fdist_filtered.most_common(30))\n",
    "fdist_filtered.plot(30,title='Frequency distribution (excluding stopwords and punctuation)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d974df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_frequencies_dict = Counter(fdist_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"src/Sainsburyâ€™s-logo-large.jpeg\"))\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", width=mask.shape[1],\n",
    "               height=mask.shape[0], max_words=1000, mask=mask).generate_from_frequencies(simple_frequencies_dict)\n",
    "# create coloring from image\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "# store to file\n",
    "plt.savefig(\"news1.png\", format=\"png\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65abd9",
   "metadata": {},
   "source": [
    "### Split date to year/month/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24535b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in tesco_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "    \n",
    "tesco_reviews['year'] = year\n",
    "tesco_reviews['month'] = month\n",
    "tesco_reviews['day'] = day\n",
    "\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in morrisons_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "\n",
    "morrisons_reviews['year'] = year\n",
    "morrisons_reviews['month'] = month\n",
    "morrisons_reviews['day'] = day    \n",
    "\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in marksandspencer_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "\n",
    "marksandspencer_reviews['year'] = year\n",
    "marksandspencer_reviews['month'] = month\n",
    "marksandspencer_reviews['day'] = day    \n",
    "\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in asda_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "\n",
    "asda_reviews['year'] = year\n",
    "asda_reviews['month'] = month\n",
    "asda_reviews['day'] = day    \n",
    "\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in aldi_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "\n",
    "aldi_reviews['year'] = year\n",
    "aldi_reviews['month'] = month\n",
    "aldi_reviews['day'] = day \n",
    "\n",
    "\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in waitrose_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "\n",
    "waitrose_reviews['year'] = year\n",
    "waitrose_reviews['month'] = month\n",
    "waitrose_reviews['day'] = day \n",
    "\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "for date in sainsburys_reviews['ymd']:\n",
    "    year.append(int(date.split('-')[0]))\n",
    "    month.append(int(date.split('-')[1]))\n",
    "    day.append(int(date.split('-')[2]))\n",
    "    \n",
    "sainsburys_reviews['year'] = year\n",
    "sainsburys_reviews['month'] = month\n",
    "sainsburys_reviews['day'] = day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99312a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"month\", data=tesco_reviews, aspect=4.0, kind='count',\n",
    "                       hue='label', order=range(3, 4), palette=['red','yellow','green'])\n",
    "    g.set_ylabels('Number of Reviews')\n",
    "    g.set_axis_labels(\"\", \"Number of Reviews\")\n",
    "    g.set_xticklabels([\"March\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f934b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesco_reviews.loc[tesco_reviews['month'] == 3]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeefff76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"month\", data=sainsburys_reviews, aspect=4.0, kind='count',\n",
    "                       hue='label', order=range(3, 4), palette=['red','yellow','green'])\n",
    "    g.set_ylabels('Number of Reviews')\n",
    "    g.set_axis_labels(\"\", \"Number of Reviews\")\n",
    "    g.set_xticklabels([\"March\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c324da",
   "metadata": {},
   "source": [
    "### Figure 1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189230ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seaborn color palette to plot pie chart\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# create pie chart using matplotlib\n",
    "def cm_to_inch(value):\n",
    "    return value/2.54\n",
    "\n",
    "explode = (0.1, 0, 0)  \n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Sainsbury's Reviews\"+\"\\n\", fontsize = 16)\n",
    "_, _, autotexts = plt.pie(sainsburys_reviews.loc[sainsburys_reviews['month'] == 3]['label'].value_counts(), \n",
    "                          labels=['Positive', 'Negative', 'Neutral'], colors=['cornflowerblue', 'tomato', 'cornsilk'], \n",
    "                          autopct='%.0f%%', textprops={'fontsize': 12}, explode=explode)\n",
    "plt.savefig('graph.png')\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_df = pd.concat([tesco_reviews, morrisons_reviews, marksandspencer_reviews, asda_reviews, aldi_reviews, waitrose_reviews], ignore_index=True, sort=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn color palette to plot pie chart\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# create pie chart using matplotlib\n",
    "def cm_to_inch(value):\n",
    "    return value/2.54\n",
    "\n",
    "explode = (0.1, 0, 0)  \n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Competition's Reviews\"+\"\\n\", fontsize = 16)\n",
    "_, _, autotexts = plt.pie(competition_df.loc[competition_df['month'] == 3]['label'].value_counts(), \n",
    "                          labels=['Positive', 'Negative', 'Neutral'], colors=['cornflowerblue', 'tomato', 'cornsilk'], \n",
    "                          autopct='%.0f%%', textprops={'fontsize': 12}, explode=explode)\n",
    "plt.savefig('graph.png')\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn color palette to plot pie chart\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# create pie chart using matplotlib\n",
    "def cm_to_inch(value):\n",
    "    return value/2.54\n",
    "\n",
    "explode = (0.1, 0, 0)  \n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Tesco's Reviews\"+\"\\n\", fontsize = 16)\n",
    "_, _, autotexts = plt.pie(tesco_reviews.loc[tesco_reviews['month'] == 3]['label'].value_counts(), \n",
    "                          labels=['Positive', 'Negative', 'Neutral'], colors=['cornflowerblue', 'tomato', 'cornsilk'], \n",
    "                          autopct='%.0f%%', textprops={'fontsize': 12}, explode=explode)\n",
    "plt.savefig('graph.png')\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac55fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sainsburys_reviews.loc[sainsburys_reviews['month'] == 3]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f6d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tesco_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96159b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(tesco_reviews.loc[(tesco_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "morrisons_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd33f77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(morrisons_reviews.loc[(morrisons_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "marksandspencer_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1f50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(marksandspencer_reviews.loc[(marksandspencer_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asda_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a40a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(asda_reviews.loc[(asda_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aldi_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b47d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(aldi_reviews.loc[(aldi_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4729c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sainsburys_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e92d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(sainsburys_reviews.loc[(sainsburys_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeab680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "waitrose_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(waitrose_reviews.loc[(waitrose_reviews['year'] == 2022)]['reviewCreatedVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ecdb8",
   "metadata": {},
   "source": [
    "### Accuraacy of models at labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b7812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sainsburys_reviews.loc[(sainsburys_reviews['label'] == sainsburys_reviews['bert_label'])])/len(sainsburys_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sainsburys_reviews.loc[(sainsburys_reviews['label'] == sainsburys_reviews['vader_label'])])/len(sainsburys_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sainsburys_reviews.loc[(sainsburys_reviews['label'] == sainsburys_reviews['textblob_label'])])/len(sainsburys_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d01cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sainsburys_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a4b92",
   "metadata": {},
   "source": [
    "### Figure 3a and 3b Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2db85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sainsburys_reviews.groupby(['day','label'])['label'].count().unstack().plot(legend=True, color = ['red', 'orange', 'green'])\n",
    "plt.title(\"Reviews submitted to Sainsbury's\")\n",
    "plt.xlabel('Day of the month')\n",
    "plt.ylabel('Number of reviews')\n",
    "plt.xticks(range(1,32, 2))\n",
    "plt.savefig('Sainsburys_reviews.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275196cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "competition_df.groupby(['day','label'])['label'].count().unstack().plot(legend=True, color = ['red', 'orange', 'green'])\n",
    "plt.title('Reviews submitted to competitors')\n",
    "plt.xlabel('Day of the month')\n",
    "plt.ylabel('Number of reviews')\n",
    "plt.xticks(range(1,32, 3))\n",
    "plt.savefig('competition_reviews_per_stars.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
